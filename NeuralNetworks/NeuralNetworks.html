<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />

<title>Tutorial</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-neural-networks" class="section level2">
<h2>Neural Networks</h2>
<p>This is an active and rapidly changing field of research. We will only cover a small portion of this vast field, but that will be enough to do some fun things.</p>
<p>We start with a weighted graph (please review the information on graphs in the <strong>mathematical background</strong>). The graph is directed and we will restrict ourselves to ones with <strong>no cycles</strong>. The graph is oriented horizontally and organized into <strong>layers</strong> which are a collection of nodes arranged vertically. The layers have a natural ordering, starting with the first, known as the <strong>input layer</strong> and culminating in the final <strong>output layer</strong>. Edges between vertices proceed from a vertex in one layer to a vertex in the next layer and, at least for now, there is no skipping of layers, nor backtracking, nor connections between nodes in the same layer. Layers in beteen the input and output layear are known as <strong>hidden layers</strong>.</p>
<p>A neural network with multiple hidden layers is a <strong>deep neural network</strong>. That’s where the term <strong>deep learning</strong> comes from. A sufficiently large neural network (in terms of nodes) with at least one hidden layer is a <strong>universal approximator</strong> Which means that it can approximate any function.</p>
<p>We associate values to each node and calculate these value in an iterative fashion based off the weights of the <em>incoming</em> edges and the <strong>values</strong> of their <strong>source nodes</strong>. This is true for all nodes except the layer one nodes (the <strong>input nodes</strong>) whose values come from outside the neural network.</p>
<p>The node value calculation is a two step process. For each node in a layer (other than the input layer) we examine the value of every immediate ancestor. The value of each ancestor is multiplied by the weight of the edge connecting the ancestor to the target node. The produces are added together and this value is, temporarily, the new node value.</p>
<p>Notice that this is, essentially, an inner product. THe ancestor nodes act as the input vector, and the weights of the connecting edges act as the other vector.</p>
<p>If we consider the subgraph comprised solely of layer <span class="math inline">\(i\)</span> and layer <span class="math inline">\(i+1\)</span> the weighted adjacency graph capatures all the weight information. The vector of <span class="math inline">\(n_i\)</span> node values would correspond to the column vector that is input into the linear transformation encoded by the matrix and the resulting <span class="math inline">\(n_{i+1}\)</span> length vector is the output.</p>
<p>Let’s denote the node values at layer <span class="math inline">\(i\)</span> by <span class="math inline">\(V_i\)</span>. The adjacency matrix of weights would then be <span class="math inline">\(W_i\)</span>. The matrix <span class="math inline">\(W_i\)</span> has dimensions <span class="math inline">\(n_i\)</span> by <span class="math inline">\(n_{i+1}\)</span>. We calculate the values at layer <span class="math inline">\(V_{i+1}\)</span> as: <span class="math inline">\(W_iv_i = v_{i+1}\)</span>.</p>
<p>If you think about it carefully, you might realize that if we stopped there the entire “layer idea” is unnecessary. We would multiply <span class="math inline">\(v_{i+1}\)</span> by <span class="math inline">\(W_{i+1}\)</span> to generate <span class="math inline">\(v_{i+1}\)</span> But why go to that trouble?</p>
<p><span class="math display">\[
\begin{aligned}
v_{i+1} &amp;= W_{i+1}v_{i+1} \\
&amp;= W_{i+1}W_iv_i
\end{aligned}
\]</span></p>
<p>But <span class="math inline">\(W_{i+1}W_i\)</span> is the matrix product of two matrices… and it could be replaced with a single matrix. BUt we do <strong>Not</strong> do this. Instead we “tweak” the values of <span class="math inline">\(v_i\)</span> before using them calculate <span class="math inline">\(v_{i+1}\)</span>.</p>
</div>
<div id="section-activation-functions" class="section level2">
<h2>Activation Functions</h2>
<p>The <em>tweaking</em> utilizes what is called an <strong>activation function</strong>. There are many of them. Classic back propogation (explained below) uses calculus and so requires that the function be <strong>differentiable</strong>. Some R packages (such as <code>neuralnet</code>) require this restriction. Others do not.</p>
<p>One popular function is <code>relu</code> which stands for <strong>rectified linear</strong>.</p>
<p>The function returns a 0 for all negative values and then passes along the original value. The graph is quite boring:</p>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-1-1.png" width="624" /></p>
<p><a href="https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7">A practical guide to relu</a> from Medium magazine (online) is good for further reading.</p>
<p>So, we calculate <span class="math inline">\(v_{i+1} = W_iv_i\)</span> using matrix mutliplication. And then replace any negative coordinate with 0.</p>
<p>This activation function has a few theoretical issues (it’s not differentiable everywhere for one), but the ease and speed of calculation makes up for it in many applications.</p>
<p>There is a differentiable version of relu called <strong>softplus</strong>:</p>
<p><span class="math display">\[
\textrm{softplus}(x) = \log(1+e^x)
\]</span></p>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-2-1.png" width="624" /></p>
<p>The two “built-in” differentiable activation functions used by the package <code>neuralnet</code> are:</p>
<ul>
<li><code>"logistic"</code>,</li>
<li>’“tanh”`.</li>
</ul>
<p>You may provide your own customized <strong>differentiable</strong> functions.</p>
<p>The logistic curve varies smoothly between 0 and 1:</p>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-3-1.png" width="624" /></p>
<p>While the <code>tanh()</code> function (the <strong>hyperbolic tangent</strong>) varies smoothly between -1 and 1:</p>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-4-1.png" width="624" /></p>
</div>
<div id="section-bias" class="section level2">
<h2>Bias</h2>
<p>One more trick/detail: Associated to individual nodes is a special value called a <strong>bias</strong>. This bias is added (which can result in subtraction if the bias is negative) to the node’s value <strong>before</strong> the activation function. It can be represented graphically be LONE nodes in the previous layer that always have a constant value of 1. This convention means that the bias arises from the weight of an edge (which will matter to us in just a second). Changing the bias is, effectively, changing the location of the threshold at which the <code>relu</code> function kicks in. (although that’s not <em>quite</em> fair since) the result is still positive values.</p>
<p>IN any event, the upshot of this procedure is that we are able to represent <strong>non-linear functions</strong>. Without the activation function, the output layer could be calculated in a single matrix multiplication from the input layers. Ergo, the only functions we could encode would all be linear.</p>
<p>However, the activation function makes things more interesting. First, if we focus our attention on ONE vertex in layer <span class="math inline">\(i+1\)</span>, then we are only considering the dot product of a single row with <span class="math inline">\(v_i\)</span>. So we are interested in solutions to <span class="math inline">\([w_j]^t \cdot v_i=0\)</span> This always forms an <span class="math inline">\(n_i-1\)</span> dimensional subspace and divides the space into two halves– those whose value is positive (and are passed on through the activation function) and those whose values are negative (and thus turned to 0).</p>
<p>In essence, the weights <span class="math inline">\(W_i\)</span> associate to each node in layer <span class="math inline">\(i+1\)</span> a <strong>half-space</strong> of node values in layer <span class="math inline">\(i\)</span>. If a weight is 0 we don’t normally think of there as being an edge– so we don’t need to deal with the pathological “all-zero” weight sitution.</p>
<p>Within the half-space the function is linear, outside the half-space the function is 0. By stacking such things together we begin to capture the functionality of <code>if-then</code>.</p>
<p>There are a large number of other activation functions which have different characteristics</p>
</div>
<div id="section-topology" class="section level2">
<h2>Topology</h2>
<p>The <strong>topology</strong> of a neural network is the layout of the graph. It is often summarized by describing</p>
<ul>
<li>The number of layers</li>
<li>The number of ndoes in each layer</li>
<li>Whether or not information can go backwards.</li>
</ul>
<p>We have already seen that a network containing multiple hidden layers is called a <strong>deep neural network</strong>. Networks for which the only connections are from nodes in one layer to nodes in a higher valued layer are called <strong>feed forwaward</strong>.</p>
<p>Networks that allow loops (edges from a node to itself) are called <strong>recurrent</strong> (or <strong>feedback networks</strong>). Some of these loops come with a <strong>delay</strong> that act as a form of memory (that will make more sense after reading the next section).</p>
<p>In image processing it is common to use a <strong>convolutional neural network</strong> that has a few additional features. We will discuss that later</p>
</div>
<div id="section-training" class="section level2">
<h2>Training</h2>
<p>Neural networks are a form of supervised learning. As with all supervised learning techniques there is a data set of interest for which the “answers” (whatever that happens to mean) are known. for example, the UCI Machine Learning repository has a commonly used data set produced by I-Cheng Yeh exploring the effects of various materials on the strength of High-Performance Concrete. The book Machine Learning in R by Brett Lantz (3rd edition) uses this as an example when they reproduce Yeh’s analysis from his 1998 paper*</p>
<p>The training process takes a data set like Yeh’s and for each row in the table the explanatory values in the row are provided to the input layer of the neural network. The output is then calculated using the process described in the last section. This is done for each row. After each calclulation, the output value is compared to the true value in the table and the <strong>weights are updated</strong>.</p>
<p>In feedforward networks the updating starts at the weights leading into the output layer and progress backwards to the input layers. The process most commonly employed is called <strong>back propogation</strong>.</p>
<p>Many people describe this complete process as a two phase procedure:</p>
<ol style="list-style-type: decimal">
<li>forward phase: Input the values into the neural net and calcualte the ouput</li>
<li>backwards phase: look at the error, and modify weights working from the output layer to the input layer</li>
</ol>
<p>One iteration of this process is known as an <strong>epoch</strong>. Without prior knowledge (like a pre-trained neural network) the weights are randomly chosen.</p>
<p>You might remember those animations we played with back in the “Math Background” when we were looking at what it means to minimize the sum of squares for a line of best fit.</p>
<p>In some way you were manually performing a similar operation. It’s not quite the same, but, there was a target value (the peak) of the graph. The values of the parameters were incrementally modified and the new result was examined. This was repeated until the desired value was achieved (the peak was reached).</p>
</div>
<div id="section-back-propogation" class="section level2">
<h2>Back Propogation</h2>
<p>Back Propogation is really related to the <strong>chain rule</strong> in calculus (for those that know what that means.) You might want to review the material in the “Math Background” referring to the chain rule.</p>
<p>In the forward stage the value of the output is generated for the current set of weights on the edges. The results in the ouptput layer (often one node) are then compared to the desired output.</p>
<p>The process starts with a data set that one wishes For a given neural network that is designed consistent with some training set</p>
<p>The input values are assigned to the input layer, the node values are calculated, and the output layer is examined.</p>
<p>I think the eigenvalues of the weight matrix will tell us something about shared subspaces. When we identify the eigen values of the weight matrix….. not quite….</p>
</div>
<div id="section-example" class="section level2">
<h2>Example</h2>
<p>We are going to use the concrete example stored in the UCI Machine Learning repository produced by I-Cheng Yeh who was exploring the effects of various materials on the strength of High-Performance Concrete. The book Machine Learning in R by Brett Lantz (3rd edition) uses this as an example when they reproduce Yeh’s analysis from his 1998 paper*</p>
<p>(more formal citation: I-Cheng Yeh, “Modeling of strength of high performance concrete using artificial neural networks,” Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). ) First we need to download the data. I’ll use the terminal command<code>wget</code>: Notice that once the file is downloaded there is no reason to do it again… so the folowing code block has <code>eval=FALSE</code>. Run it ONCE and then set <code>eval=FALSE</code>:</p>
<p>Now this is an excel file. So I will use the <code>readxl</code> package to import the data. The imported version is a tidyverse <code>tibble</code>. We will want more helpful colnames:</p>
</div>
<div id="section-normalizing-or-standardizing" class="section level2">
<h2>Normalizing (or standardizing)</h2>
<p>Read the following <a href="https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/">article about normalizing data</a></p>
<div class="panel panel-default">
<div class="panel-heading tutorial-panel-heading">Quiz</div>
<table class="table quiz-table">
<tr>
<td>

<div id="htmlwidget-0f89ffe6096546ed1856" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-0f89ffe6096546ed1856">{"x":{"question":"Which of the following are reasons to normalize the input before training a neural network?","answers":[{"option":"To put the data on a similar scale","correct":true,"message":null},{"option":"To improve convergence","correct":true,"message":null},{"option":"To linearize the comparisons","correct":false,"message":null},{"option":"To maximize the sum of the square residuals","correct":false,"message":null}],"label":"normalizing-quiz-1","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Which of the following are reasons to normalize the input before training a neural network?","a":[{"option":"To put the data on a similar scale","correct":true,"message":null},{"option":"To improve convergence","correct":true,"message":null},{"option":"To linearize the comparisons","correct":false,"message":null},{"option":"To maximize the sum of the square residuals","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-62ee0979324aec6efa86" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-62ee0979324aec6efa86">{"x":{"question":"Finding a z-score is a form of normalization","answers":[{"option":"true","correct":true,"message":null},{"option":"false","correct":false,"message":null}],"label":"normalizing-quiz-2","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Finding a z-score is a form of normalization","a":[{"option":"true","correct":true,"message":null},{"option":"false","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-5b3bcce5eff01d71f314" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-5b3bcce5eff01d71f314">{"x":{"question":"Activation functions should be chosen to conform to the structure of the output values","answers":[{"option":"true","correct":true,"message":null},{"option":"false","correct":false,"message":null}],"label":"normalizing-quiz-3","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Activation functions should be chosen to conform to the structure of the output values","a":[{"option":"true","correct":true,"message":null},{"option":"false","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
</table>
</div>
<p>The key takeaway here is that standardizing the variables is an important part of the process. Remember that neural networks are, when we use RELU as an activation function, piecewise linear. (for sufficiently large number of nodes the approximation is close enough to any non-linear function that it doesn’t matter… but the lesson still holds– standardize!)</p>
<p>The notation is a bit tricky here. In statistics I tend to use the term <strong>standardize</strong> for the process converting values to their <span class="math inline">\(z-scores\)</span>; I don’t want to confuse students with the term <strong>normalize</strong> because if the original population was already normal than <strong>normalizing</strong> is redundant. The term <strong>standardizing</strong> is a better fit because if the data is already normal, then end result is data from a standard normal distribution.</p>
<p>THe author of that link probably had similar experiences as my own. That said. My gut response is still just to call the process <strong>normalizing</strong>– whether it be</p>
<ul>
<li>subtracting the mean and dividing by the standard deviation, or</li>
<li>subtracting the min and dividing by the range, or</li>
<li>any other procedure for adjusting the input values to make them comparable.</li>
</ul>
<p>If the data looks normalish (technical term) then I would use the first approach. In most other situations, without some compelling reason, I would use the second. However, there are <strong>many</strong> other types of normalization that arise in special circumstances. Two examples that I have seen in bioinformatics applications include</p>
<ul>
<li>Divide each variable by a scaling factor so that all variables have the same geometric mean</li>
<li>Adjust values between variables so that they have the same empirical quantiles.</li>
</ul>
<p>In summary, the goal is to transform all the explanatory variables in a data set so that the values are comparable and/or to improve the efficiency and accuracy of some stage in a modelling process.</p>
<p>For our concrete data we will use the <strong>min-max normalization</strong> technique which shifts and scales a variable to have values between 0 and 1:</p>
<pre class="r"><code>normalize=function(var){
  (var-min(var))/(max(var)-min(var))
}
concrete.normalized&lt;-sapply(concrete,normalize)
concrete.normalized&lt;-as.data.frame(concrete.normalized)</code></pre>
<p>Note: The function <code>sapply</code> produces a matrix rather than a data.frame. It doesn’t really influence us much one way or the other, but columns can not be accessed in matrices using the <code>df$col</code> notation so, for the purposes of consistency, I’m keeping the training and testing data sets as data frames.</p>
<p>We can check the results of our normalization with side-by-side boxplots:</p>
<pre class="r"><code>boxplot(concrete.normalized,las=3)</code></pre>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-8-1.png" width="624" /></p>
</div>
<div id="section-training-and-testing-data" class="section level2">
<h2>Training and testing data</h2>
<p>As usual, we need to set aside some data for training and some for testing. We will use one third of the rows for testing and 2/3rds for training:</p>
</div>
<div id="section-building-the-model" class="section level2">
<h2>Building the model</h2>
<p>We will use the <code>neuralnet</code> package (so install that if necessary) which uses a function called <code>neuralnet()</code> to build the model. We will start (as was done in Brett Lantz’s <em>Machine Learning in R</em> book) with one hidden node and the logistic function as the activation function:</p>
<pre class="r"><code>library(neuralnet)
simple.model&lt;-neuralnet(data=concrete.training,strength~.,hidden=1,act.fct = &quot;logistic&quot;)</code></pre>
<pre><code>## Warning: package &#39;neuralnet&#39; was built under R version 3.6.1</code></pre>
<div class="figure">
<img src="simpleModel.png" alt="SimpleModel" />
<p class="caption">SimpleModel</p>
</div>
<p>Notice the biases.</p>
<p>If we let <code>lg</code> stand for the logistic function <span class="math inline">\(\frac{1}{1+e^{-x}}\)</span> then our model, rounded to 1 decimal place, is:</p>
<p><span class="math display">\[
\textrm{strength}=0.7-0.7 \lg(2.4 -3.9\ \textrm{cement}-2.3\ \textrm{slag}+(\cdots) -10.5\ \textrm{age})
\]</span></p>
<p>Notice that the activation function is <strong>NOT applied</strong> to the final node in this package. Let’s test our understanding. We will extract the first level of weights from the model:</p>
<pre class="r"><code>first.weights&lt;-simple.model$weights[[1]][[1]][,1]</code></pre>
<p>This includes the bias, so we will extract the explanatory values from the first training case and prepend the vector with a 1 (to represent the intercept/bias term):</p>
<pre class="r"><code>input&lt;-unlist(c(1,concrete.training[1,-9]))</code></pre>
<p>Notice that the -9 is used to remove the value for <code>strength</code>.</p>
<p>Now let’s computer “by hand” and then using the <code>predict()</code> function. Rather than using an R expression– I will hande-code the last two values to make the formula a little more intuitive:</p>
<pre class="r"><code>logistic=function(x){1/(1+exp(-x))}
0.6684915-0.7414956*logistic(sum(input*first.weights))</code></pre>
<pre><code>## [1] 0.1613026</code></pre>
<pre class="r"><code>predict(simple.model,concrete.training[1,])</code></pre>
<pre><code>##          [,1]
## 415 0.1613026</code></pre>
<p>Success! They match. So we <strong>do</strong> understand the calculation procedure.</p>
</div>
<div id="section-testing-the-model" class="section level2">
<h2>Testing the model</h2>
<p>Let’s produce all the computed and predicted values for the <em>testing set</em> and calculate the sum of squares errors:</p>
<pre class="r"><code>observed=concrete.testing$strength
predicted=predict(simple.model,concrete.testing)
sum((observed-predicted)^2)</code></pre>
<pre><code>## [1] 9.921401</code></pre>
<pre class="r"><code>plot(predicted,observed,main=&quot;Comparison of predicted and observed concrete strengths&quot;,sub=&quot;1 hidden node&quot;,xlim=c(0,1))</code></pre>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-18-1.png" width="624" /></p>
<p>Notice that the predicted values all stop around 0.7.</p>
<p>Let’s make a residual plot:</p>
<pre class="r"><code>fitted=predicted
residual=observed-fitted
plot(fitted,residual,main=&quot;Residual Plot of simple model&quot;)</code></pre>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-19-1.png" width="624" /></p>
<p>Classic <strong>heteroscedasticity</strong>. Luckily for us we are <strong>not</strong> doing a linear regression. However, the cautionary tail remains… the variance is much higher as the predicted values (aka fitted) values approach 70 percent of the maximum strength, and we are not going to be able to do a good job of predicting strengths near the maximum.</p>
</div>
<div id="section-exercise" class="section level2">
<h2>Exercise</h2>
<p><strong>Produce a model with 5 hidden nodes:</strong> and generate residual plot and sum of squares of the residuals. Call it <code>better.model</code>:</p>
<div class="tutorial-exercise" data-label="nn-exercise" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># better.model&lt;-neuralnet(data=concrete.training,strength~.,hidden=5,act.fct = &quot;logistic&quot;)
# plot(better.model)
# observed=concrete.testing$strength
# fitted=compute(better.model,concrete.testing)$net.result[,1]
# plot(fitted,observed,main=&quot;Comparison of predicted and observed concrete strengths&quot;,sub=&quot;5 hidden node&quot;,xlim=c(0,1))
# residuals=observed-fitted
# plot(fitted,residuals)
# sum(residuals^2)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-taking-it-to-the-next-level" class="section level2">
<h2>Taking it to the next level</h2>
<p>In order to improve our model we will make two changes. First, we will use the <code>softplus()</code> activation function (see earlier for review). And second we will use two hidden layers:</p>
<pre class="r"><code>softplus=function(x){log(1+exp(x))}
even.better.model&lt;-neuralnet(data=concrete.training,strength~.,hidden=c(5,5),act.fct = &quot;logistic&quot;)
even.better.model2&lt;-neuralnet(data=concrete.training,strength~.,hidden=c(5,5),act.fct = softplus)

plot(even.better.model)
plot(even.better.model2)</code></pre>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-21-1.png" width="624" /><img src="NeuralNetworks_files/figure-html/unnamed-chunk-21-2.png" width="624" /><img src="NeuralNetworks_files/figure-html/unnamed-chunk-21-3.png" width="624" /><img src="NeuralNetworks_files/figure-html/unnamed-chunk-21-4.png" width="624" /></p>
<pre><code>## [1] 4.500299</code></pre>
<pre><code>## [1] 4.34877</code></pre>
<p>The <code>softplus</code> function did a bit better than the logistic. It’s worth comparing the predicted values generated by the two of them:</p>
<p><img src="NeuralNetworks_files/figure-html/unnamed-chunk-22-1.png" width="624" /></p>
<p>We notice that softplus had a few negative values for strength (which are, of course, nonsensical), however the fit <em>was</em> improved by using <code>softplus()</code></p>
</div>
<div id="section-original-data" class="section level2">
<h2>Original Data</h2>
Once we have a decent model, the last step is to <strong>denormalize</strong> the predictions 
<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-nn-exercise-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-nn-exercise-code-editor`)), session)
output$`tutorial-exercise-nn-exercise-output` <- renderUI({
  `tutorial-exercise-nn-exercise-result`()
})
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"character","attributes":{},"value":["1.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["www"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["quiz-binding"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["quiz.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/bootstrap.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.13"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["slickquiz"]},{"type":"character","attributes":{},"value":["1.5.20"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets/lib/slickquiz"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/slickQuiz.js"]},{"type":"character","attributes":{},"value":["css/slickQuiz.css","css/slickQuizTutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43]}},"value":[{"type":"character","attributes":{},"value":["backports","base","cellranger","compiler","crayon","datasets","Deriv","digest","evaluate","graphics","grDevices","htmltools","htmlwidgets","httpuv","jsonlite","knitr","later","learnr","magrittr","markdown","methods","mime","neuralnet","pillar","pkgconfig","promises","R6","Rcpp","readxl","rlang","rmarkdown","rprojroot","shiny","stats","stringi","stringr","tibble","tools","utils","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["1.1.4","3.6.0","1.1.0","3.6.0","1.3.4","3.6.0","3.8.5","0.6.19","0.14","3.6.0","3.6.0","0.3.6","1.3","1.5.1","1.6","1.23","0.8.0","0.9.2.1","1.5","1.0","3.6.0","0.6","1.44.2","1.4.1","2.0.2","1.0.1","2.4.0","1.0.1","1.3.1","0.4.0","1.13","1.3-2","1.3.2","3.6.0","1.4.3","1.4.0","2.1.3","3.6.0","3.6.0","2.1.2","0.7","1.8-4","2.2.0"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Tutorial</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>

</html>
