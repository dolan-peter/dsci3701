<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />

<title>Regression II</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-decision-trees-reading" class="section level2">
<h2>Decision Trees Reading</h2>
<p>Perhaps a better way to make a decision is to use something more suited to classification… such as a decision tree read <a href="https://medium.com/analytics-vidhya/a-guide-to-machine-learning-in-r-for-beginners-decision-trees-c24dfd490abb">this article</a> now. (<strong>note:</strong> It is quite long. Give yourself some time to go through it. Type along in the console as you read.)</p>
<div class="panel panel-default">
<div class="panel-heading tutorial-panel-heading">Quiz</div>
<table class="table quiz-table">
<tr>
<td>

<div id="htmlwidget-d9349f3ae1530859346f" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-d9349f3ae1530859346f">{"x":{"question":"What can decision trees be used for?","answers":[{"option":"classification","correct":true,"message":null},{"option":"entropy minification","correct":false,"message":null},{"option":"regression","correct":true,"message":null},{"option":"Outlining a course of action","correct":false,"message":null}],"label":"quiz-1","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"What can decision trees be used for?","a":[{"option":"classification","correct":true,"message":null},{"option":"entropy minification","correct":false,"message":null},{"option":"regression","correct":true,"message":null},{"option":"Outlining a course of action","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-753d3e5ebeaafb6c27fb" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-753d3e5ebeaafb6c27fb">{"x":{"question":"For a categorical response value the path from root to node corresponds to which of the following:","answers":[{"option":"A classification of that case","correct":true,"message":null},{"option":"A technique for finding the median of that case","correct":false,"message":null},{"option":"A hierarchical clustering","correct":true,"message":null},{"option":"A regression parameter","correct":false,"message":null}],"label":"quiz-2","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"For a categorical response value the path from root to node corresponds to which of the following:","a":[{"option":"A classification of that case","correct":true,"message":null},{"option":"A technique for finding the median of that case","correct":false,"message":null},{"option":"A hierarchical clustering","correct":true,"message":null},{"option":"A regression parameter","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-6063040071a5ebdef290" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-6063040071a5ebdef290">{"x":{"question":"For a continuous response value the path from root to node corresponds to which of the following:","answers":[{"option":"A classification of that case","correct":false,"message":null},{"option":"A technique for finding the median of that case","correct":false,"message":null},{"option":"A sequential clustering","correct":false,"message":null},{"option":"A prediction for the center of the response variable for a specific subset of explanatory values","correct":true,"message":null}],"label":"quiz-3","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"For a continuous response value the path from root to node corresponds to which of the following:","a":[{"option":"A classification of that case","correct":false,"message":null},{"option":"A technique for finding the median of that case","correct":false,"message":null},{"option":"A sequential clustering","correct":false,"message":null},{"option":"A prediction for the center of the response variable for a specific subset of explanatory values","correct":true,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-618095e82fc92a35005f" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-618095e82fc92a35005f">{"x":{"question":"The CART algorithm tries to split data into subsets so that each subset is","answers":[{"option":"as homogeneous as possible","correct":true,"message":null},{"option":"as inhomogeneous as possible","correct":false,"message":null},{"option":"has the same centroid","correct":false,"message":null},{"option":"has as much variance as possible","correct":false,"message":null}],"label":"quiz-4","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"The CART algorithm tries to split data into subsets so that each subset is","a":[{"option":"as homogeneous as possible","correct":true,"message":null},{"option":"as inhomogeneous as possible","correct":false,"message":null},{"option":"has the same centroid","correct":false,"message":null},{"option":"has as much variance as possible","correct":false,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-12bc4f3d300352e4ca50" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-12bc4f3d300352e4ca50">{"x":{"question":"Which of the following are strengths of decision trees","answers":[{"option":"Very good at identifying relationships that are not consistent with axis lines","correct":false,"message":null},{"option":"May allow important variables to be identified","correct":true,"message":null},{"option":"Resistant to splitting on features with a large number of levels","correct":false,"message":null},{"option":"Easy interpretation","correct":true,"message":null}],"label":"quiz-5","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Which of the following are strengths of decision trees","a":[{"option":"Very good at identifying relationships that are not consistent with axis lines","correct":false,"message":null},{"option":"May allow important variables to be identified","correct":true,"message":null},{"option":"Resistant to splitting on features with a large number of levels","correct":false,"message":null},{"option":"Easy interpretation","correct":true,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-50b477ed34b6b6411c1a" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-50b477ed34b6b6411c1a">{"x":{"question":"What modification to a decision tree makes it more similar to logistic regression?","answers":[{"option":"Only binary explanatory variables are allowed","correct":false,"message":null},{"option":"Make certain to immanentize the eschaton","correct":false,"message":null},{"option":"Interior nodes are allowed to have more than two children","correct":false,"message":null},{"option":"The leaf of the tree reports the proportion of cases in the desired category instead of reporting the majority","correct":true,"message":null}],"label":"quiz-6","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"What modification to a decision tree makes it more similar to logistic regression?","a":[{"option":"Only binary explanatory variables are allowed","correct":false,"message":null},{"option":"Make certain to immanentize the eschaton","correct":false,"message":null},{"option":"Interior nodes are allowed to have more than two children","correct":false,"message":null},{"option":"The leaf of the tree reports the proportion of cases in the desired category instead of reporting the majority","correct":true,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-fc2ab49213a71ff1bb69" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-fc2ab49213a71ff1bb69">{"x":{"question":"Gini index is defined as","answers":[{"option":"The bottle matrix","correct":false,"message":null},{"option":"The information gain","correct":false,"message":null},{"option":"\\(-\\ \\displaystyle\\sum p_i \\lg p_i\\)","correct":false,"message":null},{"option":"\\(1-\\displaystyle\\sum_i p_i^2\\)","correct":true,"message":null}],"label":"quiz-7","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Gini index is defined as","a":[{"option":"The bottle matrix","correct":false,"message":null},{"option":"The information gain","correct":false,"message":null},{"option":"\\(-\\ \\displaystyle\\sum p_i \\lg p_i\\)","correct":false,"message":null},{"option":"\\(1-\\displaystyle\\sum_i p_i^2\\)","correct":true,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
<tr>
<td>

<div id="htmlwidget-e1c45e3595dfe9f4fd38" style="width:100%;height:auto;", class = "quiz html-widget">
<div class="panel panel-default">
<div class="panel-body quizArea">
</div>
</div>
</div>

<script type="application/json" data-for="htmlwidget-e1c45e3595dfe9f4fd38">{"x":{"question":"Which of the following help deal with overfitting?","answers":[{"option":"Employing cross validation techniques","correct":true,"message":null},{"option":"Avoiding tailors","correct":false,"message":null},{"option":"Removing bad data","correct":false,"message":null},{"option":"Changing the minbucket size","correct":true,"message":null}],"label":"quiz-8","skipStartButton":true,"perQuestionResponseAnswers":true,"perQuestionResponseMessaging":true,"preventUnanswered":true,"displayQuestionCount":false,"displayQuestionNumber":false,"disableRanking":true,"nextQuestionText":"","checkAnswerText":"Submit Answer","allowRetry":false,"randomSortAnswers":false,"json":{"info":{"name":"","main":""},"questions":[{"q":"Which of the following help deal with overfitting?","a":[{"option":"Employing cross validation techniques","correct":true,"message":null},{"option":"Avoiding tailors","correct":false,"message":null},{"option":"Removing bad data","correct":false,"message":null},{"option":"Changing the minbucket size","correct":true,"message":null}],"correct":"Correct!","incorrect":"Incorrect."}]}},"evals":[],"jsHooks":[]}</script>
</td>
</tr>
</table>
</div>
</div>
<div id="section-decision-trees-practical" class="section level2">
<h2>Decision trees Practical</h2>
<p>Similar to the first regression tutorial let’s use the UCLA data for our exploration:</p>
<pre class="r"><code># Load CART packages
library(rpart)
library(rpart.plot)
df &lt;- read.csv(&quot;https://stats.idre.ucla.edu/stat/data/binary.csv&quot;)
df$rank=factor(df$rank) # Best for rank to be a factor
admit.tree=rpart(admit ~ gre + gpa+rank, data=df,method=&quot;class&quot;)
prp(admit.tree)</code></pre>
<p><img src="Regression-II_files/figure-html/unnamed-chunk-1-1.png" width="624" /></p>
<p>So, given a row in the table we follow the directions by answering a series of yes/no questions:</p>
<p>Let’s use the first row as an example.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\textrm{gpa}&lt;3.4\)</span> NO (go right)</li>
<li><span class="math inline">\(\textrm{rank}\)</span> is 2, 3, or 4. YES (go left)</li>
<li>Prediction is 0</li>
</ol>
<p>Just like the results from the logistic regression we can use the model to make a prediction.</p>
<p>First look at the first few predictions:</p>
<pre class="r"><code>tree.p=predict(admit.tree)
head(tree.p)</code></pre>
<pre><code>##           0         1
## 1 0.6966292 0.3033708
## 2 0.6966292 0.3033708
## 3 0.2500000 0.7500000
## 4 0.8686869 0.1313131
## 5 0.8686869 0.1313131
## 6 0.3000000 0.7000000</code></pre>
<p>You can see that the tree puts 70% chance that row 1 is a 0 and a 30% chance that it is a 1. We want to pick the larger of the two values. We can, fairly easily, look at the column for 1. If it is higher than 0.5 then we’ll choose 1 (since each row must add to 1). I choose higher than 0.5 instead of higher than <em>or equal</em> to 0.5 since there are more 0’s… so if we don’t know any better, might as well choose the more common one. Note that the innermost expression evaluates to <code>TRUE</code> and <code>FALSE</code>, but <code>as.numeric</code> turns <code>FALSE</code> to 0 and <code>TRUE</code> to 1:</p>
<p>Let’s make the confusion matrix for this classification:</p>
<pre class="r"><code>pv=predict(admit.tree,type=&quot;class&quot;)
table(df$admit,pv)</code></pre>
<pre><code>##    pv
##       0   1
##   0 249  24
##   1  73  54</code></pre>
<p>Our accuracy is <span class="math inline">\(\frac{249+54}{400} = 0.7575\)</span>. That’s better than before. Also our Type I and Type II error rates are more balanced.</p>
<p>Notice that <strong>it is impossible</strong> to guess everything correctly. Rows 15 and 166 on the table are identical in all respects <strong>except</strong> the value of <em>admit</em>:</p>
<pre class="r"><code>kable(df[c(15,166),]) %&gt;%kable_styling()</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
admit
</th>
<th style="text-align:right;">
gre
</th>
<th style="text-align:right;">
gpa
</th>
<th style="text-align:left;">
rank
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
15
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
700
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
166
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
700
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
1
</td>
</tr>
</tbody>
</table>
<p>Now… MOST of the combinations of values are distinct… which means that one <strong>could</strong>, produce a very exhaustive list of special cases to make VERY accurate predictions… HOWEVER that would only work on the specific data-set and would be extremely unlikely to transfer well to new data. This problem is known as <strong>over-fitting</strong>.</p>
<p>However… look at the tree again and think about what it’s saying… The first thing it looks at is a student’s gpa. Is it low (below 3.4) or high? That’s the first devision. If the GPA is low than a student who does not come from a well-ranked school is weeded out. If they DO come from a higher ranked school then they’d better have a pretty impressive GRE score. A score of less than 730 rules them out… otherwise they’re in. (probabilistically speaking of course)</p>
<p>On the other hand.. if the GPA is higher and the school is top ranked… then the student is accepted if the school is low ranked 3 or 4 the student is rejected. After this the GPA is taken into consideration. This one gets a bit… <em>weird</em> If your GPA iS between 3.4 and 3.5 then you’re accepted. If your GPA is between 3.5 and 3.7 you are rejected. Otherwise your GRE is used to determine your acceptance.</p>
<p>Let’s add <code>extra=1</code> to the <code>prp</code> function. This will add the number of rows correctly (and incorrectly) classified:</p>
<pre class="r"><code>prp(admit.tree,extra=1)</code></pre>
<p><img src="Regression-II_files/figure-html/unnamed-chunk-5-1.png" width="624" /></p>
<p>This provides us a better sense from whence the errors in prediction are arising…. first off– notice that no matter what occurs at the first split– a rank 3 or rank 4 school is given a best guess of 0… so in that subset… without taking anything else into consideration just saying predicting “reject” will be correct almost 79% of the time… So that’s a pretty good indicator. It’s not that the tree couldn’t decide to be more aggressive in its branching… but that defeats part of the purpose– the goal is to identify <em>trends</em>– simplifying patterns that tell us something meaningful about the overall system– not to blindly pursue accuracy at the cost of sensibiity.</p>
<p>The <code>summary</code> provides another way to view the rules. Note that some nodes may be “collapsed” and not appear in the graphed tree:</p>
<div style="max-height: 300px;float: left;width: 100%;overflow-y: auto;">
<pre class="r"><code>summary(admit.tree)</code></pre>
<pre><code>## Call:
## rpart(formula = admit ~ gre + gpa + rank, data = df, method = &quot;class&quot;)
##   n= 400 
## 
##           CP nsplit rel error    xerror       xstd
## 1 0.06299213      0 1.0000000 1.0000000 0.07330768
## 2 0.02362205      2 0.8740157 0.9527559 0.07233710
## 3 0.01574803      4 0.8267717 0.9055118 0.07127507
## 4 0.01000000      8 0.7637795 1.0000000 0.07330768
## 
## Variable importance
##  gpa rank  gre 
##   42   36   22 
## 
## Node number 1: 400 observations,    complexity param=0.06299213
##   predicted class=0  expected loss=0.3175  P(node) =1
##     class counts:   273   127
##    probabilities: 0.682 0.318 
##   left son=2 (208 obs) right son=3 (192 obs)
##   Primary splits:
##       gpa  &lt; 3.415 to the left,  improve=8.867821, (0 missing)
##       rank splits as  RRLL,      improve=7.781937, (0 missing)
##       gre  &lt; 510   to the left,  improve=4.843976, (0 missing)
##   Surrogate splits:
##       gre  &lt; 610   to the left,  agree=0.645, adj=0.260, (0 split)
##       rank splits as  RLRL,      agree=0.540, adj=0.042, (0 split)
## 
## Node number 2: 208 observations,    complexity param=0.01574803
##   predicted class=0  expected loss=0.2163462  P(node) =0.52
##     class counts:   163    45
##    probabilities: 0.784 0.216 
##   left son=4 (99 obs) right son=5 (109 obs)
##   Primary splits:
##       rank splits as  RRLL,      improve=2.731978, (0 missing)
##       gre  &lt; 750   to the left,  improve=2.515925, (0 missing)
##       gpa  &lt; 3.235 to the right, improve=1.053296, (0 missing)
##   Surrogate splits:
##       gre &lt; 530   to the left,  agree=0.582, adj=0.121, (0 split)
##       gpa &lt; 3.225 to the right, agree=0.553, adj=0.061, (0 split)
## 
## Node number 3: 192 observations,    complexity param=0.06299213
##   predicted class=0  expected loss=0.4270833  P(node) =0.48
##     class counts:   110    82
##    probabilities: 0.573 0.427 
##   left son=6 (160 obs) right son=7 (32 obs)
##   Primary splits:
##       rank splits as  RLLL,      improve=8.0083330, (0 missing)
##       gre  &lt; 450   to the left,  improve=1.1737770, (0 missing)
##       gpa  &lt; 3.945 to the left,  improve=0.5037879, (0 missing)
## 
## Node number 4: 99 observations
##   predicted class=0  expected loss=0.1313131  P(node) =0.2475
##     class counts:    86    13
##    probabilities: 0.869 0.131 
## 
## Node number 5: 109 observations,    complexity param=0.01574803
##   predicted class=0  expected loss=0.293578  P(node) =0.2725
##     class counts:    77    32
##    probabilities: 0.706 0.294 
##   left son=10 (99 obs) right son=11 (10 obs)
##   Primary splits:
##       gre  &lt; 730   to the left,  improve=3.63727200, (0 missing)
##       gpa  &lt; 2.905 to the left,  improve=0.33841060, (0 missing)
##       rank splits as  RL--,      improve=0.02221607, (0 missing)
## 
## Node number 6: 160 observations,    complexity param=0.02362205
##   predicted class=0  expected loss=0.3625  P(node) =0.4
##     class counts:   102    58
##    probabilities: 0.637 0.362 
##   left son=12 (89 obs) right son=13 (71 obs)
##   Primary splits:
##       rank splits as  -RLL,      improve=1.4024450, (0 missing)
##       gre  &lt; 650   to the left,  improve=1.1404990, (0 missing)
##       gpa  &lt; 3.945 to the left,  improve=0.7032468, (0 missing)
##   Surrogate splits:
##       gpa &lt; 3.515 to the right, agree=0.594, adj=0.085, (0 split)
## 
## Node number 7: 32 observations
##   predicted class=1  expected loss=0.25  P(node) =0.08
##     class counts:     8    24
##    probabilities: 0.250 0.750 
## 
## Node number 10: 99 observations
##   predicted class=0  expected loss=0.2525253  P(node) =0.2475
##     class counts:    74    25
##    probabilities: 0.747 0.253 
## 
## Node number 11: 10 observations
##   predicted class=1  expected loss=0.3  P(node) =0.025
##     class counts:     3     7
##    probabilities: 0.300 0.700 
## 
## Node number 12: 89 observations
##   predicted class=0  expected loss=0.3033708  P(node) =0.2225
##     class counts:    62    27
##    probabilities: 0.697 0.303 
## 
## Node number 13: 71 observations,    complexity param=0.02362205
##   predicted class=0  expected loss=0.4366197  P(node) =0.1775
##     class counts:    40    31
##    probabilities: 0.563 0.437 
##   left son=26 (55 obs) right son=27 (16 obs)
##   Primary splits:
##       gpa &lt; 3.495 to the right, improve=2.600032, (0 missing)
##       gre &lt; 500   to the left,  improve=1.751006, (0 missing)
## 
## Node number 26: 55 observations,    complexity param=0.01574803
##   predicted class=0  expected loss=0.3636364  P(node) =0.1375
##     class counts:    35    20
##    probabilities: 0.636 0.364 
##   left son=52 (26 obs) right son=53 (29 obs)
##   Primary splits:
##       gpa &lt; 3.73  to the left,  improve=2.8948640, (0 missing)
##       gre &lt; 690   to the right, improve=0.3878788, (0 missing)
##   Surrogate splits:
##       gre &lt; 610   to the left,  agree=0.582, adj=0.115, (0 split)
## 
## Node number 27: 16 observations
##   predicted class=1  expected loss=0.3125  P(node) =0.04
##     class counts:     5    11
##    probabilities: 0.312 0.688 
## 
## Node number 52: 26 observations
##   predicted class=0  expected loss=0.1923077  P(node) =0.065
##     class counts:    21     5
##    probabilities: 0.808 0.192 
## 
## Node number 53: 29 observations,    complexity param=0.01574803
##   predicted class=1  expected loss=0.4827586  P(node) =0.0725
##     class counts:    14    15
##    probabilities: 0.483 0.517 
##   left son=106 (9 obs) right son=107 (20 obs)
##   Primary splits:
##       gre &lt; 690   to the right, improve=0.8827586, (0 missing)
##       gpa &lt; 3.945 to the left,  improve=0.5029606, (0 missing)
## 
## Node number 106: 9 observations
##   predicted class=0  expected loss=0.3333333  P(node) =0.0225
##     class counts:     6     3
##    probabilities: 0.667 0.333 
## 
## Node number 107: 20 observations
##   predicted class=1  expected loss=0.4  P(node) =0.05
##     class counts:     8    12
##    probabilities: 0.400 0.600</code></pre>
</div>
<p>At each stage of the game the decision tree is trying to <strong>partition</strong> the data into two sets based upon some “rule. Each set is given a”prediction“. If the split can successfully improve discrimination beyond a certain threshold then it is added. There are usually restrictions on both <strong>depth</strong> and <strong>bin size</strong>. For example, the process, typically, stops trying when it reaches a depth of 30, or when the partition under consideration has 5 or fewer observations. This generates a tree that is, almost certianly, too complicated (recall what we said about <em>over fitting</em> earlier).</p>
<p>The second step is to <strong>trim</strong> the tree. The <code>rpart</code> function does some of this automatically– you might wish to do some more. The <code>prune()</code> function allows you to do this</p>
<p>Read <a href="https://dzone.com/articles/how-to-create-a-perfect-decision-tree">this DZone article on decision trees</a></p>
<p>There are a number of decisions to make about both what the model is saying, as well as how good of a job it is doing.</p>
<table>
<colgroup>
<col width="64%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>rpart(...,method=&quot;class&quot;)</code></td>
<td>Build the classification tree. Uses conventions similar to <code>lm()</code></td>
</tr>
<tr class="even">
<td><code>prp(tree)</code></td>
<td>Makes a graph of tree (from <code>rpart.plot</code> package)</td>
</tr>
<tr class="odd">
<td><code>summary(tree)</code></td>
<td>Shows the rules, the call, the printcp table, and variable importance.</td>
</tr>
<tr class="even">
<td><code>plotcp(tree)</code></td>
<td>Produce the complexity plot.</td>
</tr>
<tr class="odd">
<td><code>printcp(tree)</code></td>
<td>Table of the complexity plot</td>
</tr>
<tr class="even">
<td><code>print(tree)</code></td>
<td>Essentially a summary</td>
</tr>
<tr class="odd">
<td><code>PRESS(tree)</code></td>
<td>Should work but doesn’t</td>
</tr>
<tr class="even">
<td><code>prune(tree)</code></td>
<td>Prune the tree</td>
</tr>
</tbody>
</table>
<p>In general, we assess by making a confusion matrix via <code>predict()</code> and <code>table()</code>. More particularly, <code>rpart</code> performs cross-validation and this information is accessed graphically via <code>plotcp()</code> and in table form as <code>printcp()</code>. It is also included in <code>summary()</code></p>
<pre><code>The x-error is the cross-validation error (rpart has built-in cross validation). You use the 3 columns, rel_error, xerror and xstd together to help you choose where to prune the tree.

Each row represents a different height of the tree. In general, more levels in the tree mean that it has lower classification error on the training. However, you run the risk of overfitting. Often, the cross-validation error will actually grow as the tree gets more levels (at least, after the &#39;optimal&#39; level).

A rule of thumb is to choose the lowest level where the rel_error + xstd &lt; xerror.

If you run plotcp on your output it will also show you the optimal place to prune the tree.

From https://stackoverflow.com/questions/29197213/what-is-the-difference-between-rel-error-and-x-error-in-a-rpart-decision-tree?rq=1
</code></pre>
<pre><code>I would like to add some info to \@Harold Ship&#39;s answer. Actually, there are three ways to select the optimal cp value for pruning:

Use the first level (i.e. least nsplit) with minimum xerror. The first level only kicks in when there are multiple level having same, minimum xerror. This is the most common used method.

Use the first level where xerror falls into the ±1 xstd range of min(xerror), i.e., xerror &lt; min(xerror) + xstd, the level whose xerror is at or below horizontal line. This method takes into account the variability of xerror resulting from cross-validation.

Note: rel_error should NOT be used in pruning.

(A rarely used method) Use the first level where xerror ± xstd overlaps with min(xerror) ± xstd. i.e., the level whose lower limit is at or below horizontal line.</code></pre>
<p><strong>Exercise:</strong> Now read <a href="http://uc-r.github.io/regression_trees">this article</a> and reproduce their code (no copy-pasting allowed!) which discusses using regression trees to categorize more than just a binary response. It’s the same basic idea, but the prediction is for more than just 0 or 1. Notice that the <code>rpart()</code> function is using <code>method=&quot;anova&quot;</code> rather than <code>method=&quot;class&quot;</code>. Itt also shows examples of using <strong>bagging</strong> (see Week 8 notes for more information)</p>
<p>Pay special attention to the discussion around</p>
<ul>
<li>The PRESS Statistic</li>
<li>Relative Error</li>
<li>Cross-Validation X error</li>
</ul>
<p><code>plotcp(model)</code>, <code>printcp(model)</code></p>
<!--
DEFINE (these are, mostly, in Week 8 and an earlier tutorial)
CROSS-VALIDATION ERROR
PRESS STATISTIC
MSE
-->
<pre class="r"><code>library(rsample)</code></pre>
<pre><code>## Loading required package: tidyr</code></pre>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:kableExtra&#39;:
## 
##     group_rows</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(rpart)
library(rpart.plot)
library(ipred)
library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre class="r"><code>set.seed(123)
ames_split &lt;- initial_split(AmesHousing::make_ames(),prop=0.7)
ames_train &lt;- training(ames_split)
ames_test &lt;- testing(ames_split)

m1 &lt;- rpart(
  formula=Sale_Price ~ .,
  data   =ames_train,
  method =&quot;anova&quot;
)

rpart.plot(m1) #plot the tree</code></pre>
<p><img src="Regression-II_files/figure-html/regression-exercise-external%20exercise-1.png" width="624" /></p>
<pre class="r"><code>plotcp(m1)     #plot complexity parameter table</code></pre>
<p><img src="Regression-II_files/figure-html/regression-exercise-external%20exercise-2.png" width="624" /></p>
</div>
<div id="section-random-forests" class="section level2">
<h2>Random Forests</h2>
<p>This is a pretty small data set. When the data set is larger there may be conflicting choices, more noise, and other issues that make producing the optimal decision tree problematic. One approach is to pick a random subset of the data (rows <strong>and</strong> columns) and build a tree from that subset. Repeat this process many, many times. The rows are selected <strong>with replacement</strong> (This is known as <strong>bootstrapping</strong>).</p>
<p>I want to reiterate a few details about the <strong>random subset</strong> idea. For random forests this is more than just selecting random rows with replacement. The explanatory variables are ALSO selected at random. As the many random trees are produced, the various explanatory variables involved in the rules are monitored and a running tally of <strong>the most important variables</strong> are produced.</p>
<p>There are many <strong>aggregation techniques</strong> that do something similar. Bootstrap aggregation (<strong>bagging</strong>) is one such example. However, randomly producing trees can generate many trees that are too similar. This reduces the effectiveness of the technique. The <strong>random forest</strong> idea</p>
<p><strong>EXERCISE:</strong> Read the <a href="https://uc-r.github.io/random_forests">following tutorial from uc-r</a> and reproduce their example. Do <strong>NOT</strong> copy and paste.</p>
<pre class="r"><code>library(rsample)      # data splitting 
library(randomForest) # basic implementation</code></pre>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: &#39;randomForest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine</code></pre>
<pre class="r"><code>library(ranger)       # a faster implementation of randomForest</code></pre>
<pre><code>## 
## Attaching package: &#39;ranger&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:randomForest&#39;:
## 
##     importance</code></pre>
<pre class="r"><code>library(caret)        # an aggregator package for performing many machine learning models
library(h2o)          # an extremely fast java-based platform</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit http://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;h2o&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     &amp;&amp;, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code>library(AmesHousing)
set.seed(123)
ames_split&lt;-initial_split(AmesHousing::make_ames(),prop=0.7)
ames_train &lt;- training(ames_split)</code></pre>
<!--
POTENTIALLY Read [Leo Breiman and ADele Cutler's manual on Random Forests](https://www.stat.berkeley.edu/~breiman/RandomForests/).  

#```{r}
#cars<-read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data")
#```
## Boosted Regression
The package `gbm` will perform boosted regression and the summary provides a nice summary of the relative influence of the explanatory variables:

#```{r}
library(gbm)
test=gbm(data=df,admit~gre+gpa+rank)
summary(test)
#```


## Non parameteric regression

(Borrowing heavily from Chapter 18 of John Fox's Applied Regression Analysis and Generalized Liner Models)

The techniques we have discussed earlier are all based on an underlying model whose exact from is determined by numeric **parameters**.  The process of regression determines reasonable values for these parameters.  There are other techniques that do not 

One technique that does not rely upon an underlying parametric model for the data is known as **local linear regression** (or **loess**).  As with most non-parametric forms of regressin

MOVE to another tutorial
-->

<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"character","attributes":{},"value":["1.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["www"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["htmlwidgets"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["quiz-binding"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["quiz.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/bootstrap.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["localforage"]},{"type":"character","attributes":{},"value":["1.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/localforage"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["localforage.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.9.2.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["slickquiz"]},{"type":"character","attributes":{},"value":["1.5.20"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["htmlwidgets/lib/slickquiz"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/slickQuiz.js"]},{"type":"character","attributes":{},"value":["css/slickQuiz.css","css/slickQuizTutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.9.2.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.1.0"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104]}},"value":[{"type":"character","attributes":{},"value":["AmesHousing","assertthat","backports","base","bitops","caret","class","codetools","colorspace","compiler","crayon","data.table","datasets","digest","dplyr","evaluate","foreach","furrr","future","generics","ggplot2","globals","glue","gower","graphics","grDevices","grid","gtable","h2o","highr","hms","htmltools","htmlwidgets","httpuv","httr","ipred","iterators","jsonlite","kableExtra","knitr","later","lattice","lava","lazyeval","learnr","lifecycle","listenv","lubridate","magrittr","markdown","MASS","Matrix","methods","mime","ModelMetrics","munsell","nlme","nnet","parallel","pillar","pkgconfig","plyr","prodlim","promises","purrr","R6","randomForest","ranger","Rcpp","RCurl","readr","recipes","reshape2","rlang","rmarkdown","rpart","rpart.plot","rprojroot","rsample","rstudioapi","rvest","scales","shiny","splines","stats","stats4","stringi","stringr","survival","tibble","tidyr","tidyselect","timeDate","tools","utils","vctrs","viridisLite","webshot","withr","xfun","xml2","xtable","yaml","zeallot"]},{"type":"character","attributes":{},"value":["0.0.3","0.2.1","1.1.4","3.5.3","1.0-6","6.0-84","7.3-15","0.2-16","1.4-1","3.5.3","1.3.4","1.12.2","3.5.3","0.6.21","0.8.3","0.14","1.4.7","0.1.0","1.14.0","0.0.2","3.2.1","0.12.4","1.3.1","0.2.1","3.5.3","3.5.3","3.5.3","0.3.0","3.26.0.2","0.8","0.5.1","0.3.6","1.3","1.5.2","1.4.1","0.9-9","1.0.12","1.6","1.1.0","1.25","0.8.0","0.20-38","1.6.6","0.2.2","0.9.2.1","0.1.0","0.7.0","1.7.4","1.5","1.1","7.3-51.4","1.2-17","3.5.3","0.7","1.2.2","0.5.0","3.1-141","7.3-12","3.5.3","1.4.2","2.0.3","1.8.4","2018.04.18","1.0.1","0.3.2","2.4.0","4.6-14","0.11.2","1.0.2","1.95-4.12","1.3.1","0.1.7","1.4.3","0.4.0","1.15","4.1-15","3.0.8","1.3-2","0.0.5","0.10","0.3.4","1.0.0","1.3.2","3.5.3","3.5.3","3.5.3","1.4.3","1.4.0","2.44-1.1","2.1.3","1.0.0","0.2.5","3043.102","3.5.3","3.5.3","0.2.0","0.3.0","0.5.1","2.1.2","0.9","1.2.2","1.8-4","2.2.0","0.1.0"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Regression II</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>

</html>
